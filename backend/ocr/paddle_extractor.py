import os
import re
import logging
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple

import cv2
import numpy as np
import pandas as pd
from io import StringIO
from paddleocr import PPStructure

from .image_processor import ImagePreprocessor
from config import ENABLE_PREPROCESSING

logger = logging.getLogger(__name__)


class PaddleExtractor:
    """
    PP-Structure table extractor (restored first-pass behavior + optional crop second-pass).

    FIX:
    - Ensure continuation/wrapped text stays in the SAME cell (Description) for the same line item:
      if SL is empty and row is mostly text -> append to previous row's description.
    - Remove duplicated continuation text that leaks into Qty column (common PP-Structure artifact).
    """

    HEADER_KEYWORDS = (
        # generic
        "id", "item", "code", "desc", "description",
        "qty", "quantity", "qnty", "units", "um",
        "rate", "price", "amount", "total",
        "product", "service", "hsn", "sac", "taxable", "igst", "cgst", "sgst", "cess",
        # your sample invoice headers
        "no.", "no", "net price", "net worth", "vat", "vat [%]", "gross worth"
    )

    STOP_KEYS = (
        "subtotal", "sub total", "sub-total",
        "tax", "tax rate", "gst", "vat", "igst", "cgst", "sgst",
        "grand total", "total due", "amount due", "balance due",
        "round off", "roundoff", "discount", "shipping", "handling", "delivery",
        "net amount", "gross amount",
        "summary"
    )

    def __init__(self, use_gpu: bool = False):
        self.use_gpu = use_gpu
        self.preprocessor = ImagePreprocessor()

        # First pass: keep your original working config
        self.doc_engine = PPStructure(
            use_cuda=use_gpu,
            use_pdf2image_cuda=use_gpu,
            lang="ch",
            recovery=False,
            layout=True,
            table=True,
            ocr=True,
        )

        # Second pass: table-only engine (used only if first pass fails)
        self.table_engine = PPStructure(
            use_cuda=use_gpu,
            use_pdf2image_cuda=use_gpu,
            lang="ch",
            recovery=True,
            layout=False,
            table=True,
            ocr=True,
        )

        logger.info(f"âœ… PaddleOCR PP-Structure initialized | GPU: {use_gpu}")

    # ==================== MAIN ====================

    def extract_from_image(self, image_path: str) -> Dict[str, Any]:
        preprocessed_path = None
        try:
            img = cv2.imread(image_path)
            if img is None:
                raise ValueError(f"Failed to read image: {image_path}")
            logger.info(f"ðŸ“¸ Image loaded: {img.shape}")

            if ENABLE_PREPROCESSING:
                logger.info("ðŸ”„ Preprocessing enabled...")
                img = self.preprocessor.auto_rotate_image(img)
                img = self.preprocessor.enhance_image(img)
                p = Path(image_path)
                preprocessed_path = str(p.with_name(p.stem + "_preprocessed" + p.suffix))
                cv2.imwrite(preprocessed_path, img)
                logger.info("âœ… Preprocessing complete")

            logger.info("ðŸ”„ Running PP-Structure extraction (first pass)...")
            doc_result = self.doc_engine(img, return_ocr_result_in_table=True)
            logger.info(f"âœ… PP-Structure complete: {len(doc_result)} regions found")

            table_blocks = self.extract_and_reconstruct_tables(doc_result, img)
            extracted_data = self._parse_results(doc_result, table_blocks)
            return {"status": "success", "data": extracted_data}

        except Exception as e:
            logger.exception(f"âŒ Extraction error: {e}")
            return {"status": "error", "message": str(e)}
        finally:
            if preprocessed_path and os.path.exists(preprocessed_path):
                try:
                    os.remove(preprocessed_path)
                except Exception as e:
                    logger.warning(f"âš ï¸ Could not remove temp file: {e}")

    # ==================== TABLES ====================

    def extract_and_reconstruct_tables(
        self,
        docresult: List[Dict[str, Any]],
        img: Optional[np.ndarray] = None
    ) -> List[Dict[str, Any]]:
        """
        1) First-pass region: rec_res + cell_bbox/boxes -> grid
        2) If grid missing and image available: crop bbox and run second-pass engine
        3) Else HTML
        4) Else tokens fallback
        """
        out: List[Dict[str, Any]] = []
        logger.info("=" * 80)
        logger.info("ðŸ“Š TABLE EXTRACTION")
        logger.info("=" * 80)

        table_count = 0
        for region in docresult:
            if region.get("type") != "table":
                continue

            table_count += 1
            logger.info(f"\nðŸ“‹ TABLE {table_count}")

            res = region.get("res") or {}
            html = res.get("html")
            rec_res = res.get("rec_res") or res.get("recres") or []
            boxes = res.get("boxes") or res.get("box") or []
            cell_bbox = res.get("cell_bbox") or res.get("cellBbox") or []

            canonical_rows: Optional[List[List[str]]] = None
            raw_grid: Optional[List[List[str]]] = None

            # METHOD 1: first-pass cell reconstruction
            cells = self._cells_from_pp_table(rec_res, cell_bbox=cell_bbox, boxes=boxes)
            if cells:
                logger.info(f"  ðŸ”„ METHOD 1: OCR cells (cells={len(cells)})...")
                raw_grid = self._grid_from_cells(cells)
                if raw_grid:
                    canonical_rows = self._ensure_header_row(raw_grid)
                    canonical_rows = self._merge_continuations_and_fix_dupes(canonical_rows)
                    logger.info(
                        f"  âœ… SUCCESS: {len(canonical_rows)} rows Ã— {max(len(r) for r in canonical_rows)} cols"
                    )

            # METHOD 1b: optional second pass on crop if first pass failed
            if canonical_rows is None and img is not None:
                crop = self._safe_crop(img, region.get("bbox"), pad=10)
                if crop is not None:
                    try:
                        logger.info("  ðŸ”„ METHOD 1b: second-pass table_engine on crop...")
                        second = self.table_engine(crop, return_ocr_result_in_table=True)
                        res2 = self._first_table_res(second)
                        if res2:
                            rec_res2 = res2.get("rec_res") or res2.get("recres") or []
                            boxes2 = res2.get("boxes") or res2.get("box") or []
                            cell_bbox2 = res2.get("cell_bbox") or res2.get("cellBbox") or []
                            cells2 = self._cells_from_pp_table(rec_res2, cell_bbox=cell_bbox2, boxes=boxes2)
                            if cells2:
                                raw_grid = self._grid_from_cells(cells2)
                                if raw_grid:
                                    canonical_rows = self._ensure_header_row(raw_grid)
                                    canonical_rows = self._merge_continuations_and_fix_dupes(canonical_rows)
                                    logger.info("  âœ… SECOND PASS SUCCESS")
                    except Exception as e:
                        logger.debug(f"  âš ï¸ Second pass failed: {e}")

            # METHOD 2: HTML
            if canonical_rows is None and html:
                logger.info(f"  ðŸ”„ METHOD 2: HTML ({len(html)} chars)...")
                raw_grid = self._parse_html_table(html)
                if raw_grid:
                    canonical_rows = self._ensure_header_row(raw_grid)
                    canonical_rows = self._merge_continuations_and_fix_dupes(canonical_rows)
                    logger.info(f"  âœ… HTML rows: {len(canonical_rows)}")

            # METHOD 3: tokens
            if canonical_rows is None and rec_res:
                logger.info("  ðŸ”„ METHOD 3: token fallback...")
                tokens = self._tokens_from_rec_res(rec_res)
                if tokens:
                    raw_grid = [["Item", "Text"]] + [[str(i + 1), t] for i, t in enumerate(tokens)]
                    canonical_rows = raw_grid
                    logger.warning(f"  âš ï¸ FALLBACK tokens: {len(tokens)}")

            if canonical_rows is None:
                logger.error(f"  âŒ TABLE {table_count}: no usable grid")
                continue

            table_block = {
                "canonicalrows": canonical_rows,
                "canonical_rows": canonical_rows,
                "raw_grid": raw_grid or canonical_rows,
                "html": self.grid_to_html(canonical_rows),
                "rec_res": rec_res,
                "cell_bbox": cell_bbox,
                "boxes": boxes,
                "row_count": len(canonical_rows),
                "col_count": max((len(r) for r in canonical_rows), default=0),
                "bbox": region.get("bbox"),
            }
            out.append(table_block)
            logger.info(f"  ðŸ“¤ Added table {table_count}")

        logger.info("\n" + "=" * 80)
        logger.info(f"ðŸ“Š Total tables extracted: {len(out)}")
        logger.info("=" * 80)
        return out

    # ==================== FIX: keep continuation in same cell ====================

    def _merge_continuations_and_fix_dupes(self, grid: List[List[str]]) -> List[List[str]]:
        """
        Works on any grid (wide or 5-col). Goal:
        - If a row has no SL/ID but has description-like text, append it to previous row's description cell.
        - If the same continuation text appears in another column (often Qty), clear that duplicate.
        """
        if not grid or len(grid) < 3:
            return grid

        header = grid[0]
        ncols = max(len(r) for r in grid)
        fixed = []
        for r in grid:
            rr = list(r) + [""] * (ncols - len(r))
            fixed.append(rr[:ncols])

        # find likely columns
        def find_col(keys: Tuple[str, ...]) -> Optional[int]:
            for i, c in enumerate(header):
                t = (c or "").strip().lower()
                if any(k in t for k in keys):
                    return i
            return None

        i_sl = find_col(("sl", "s.no", "no", "id"))
        i_desc = find_col(("description", "desc", "item", "product", "particulars"))
        i_qty = find_col(("qty", "quantity", "um", "units"))

        # if desc not found, fall back to column 1 (common: No. at 0, Desc at 1)
        if i_desc is None:
            i_desc = 1 if ncols > 1 else 0

        out = [fixed[0]]
        for row in fixed[1:]:
            sl = (row[i_sl].strip() if (i_sl is not None and i_sl < ncols) else "").strip()
            desc = (row[i_desc] or "").strip()

            # consider a "continuation" row if SL empty and desc has text
            # and the row doesn't look like a totals/summary separator
            row_text = " ".join((c or "").strip().lower() for c in row if (c or "").strip())
            is_stop = any(k in row_text for k in self.STOP_KEYS)

            # If SL empty and desc exists -> continuation row
            if (not sl) and desc and (not is_stop) and len(out) > 1:
                # append to previous description
                out[-1][i_desc] = (out[-1][i_desc].strip() + " " + desc).strip()

                # clear duplicates of the same continuation in other columns (e.g. Qty)
                if i_qty is not None and i_qty < ncols:
                    if (row[i_qty] or "").strip() == desc:
                        row[i_qty] = ""

                # do not keep this row
                continue

            out.append(row)

        return out

    # ==================== HELPERS ====================

    @staticmethod
    def _first_table_res(result: Any) -> Optional[Dict[str, Any]]:
        if not isinstance(result, list):
            return None
        for r in result:
            if isinstance(r, dict) and r.get("type") == "table":
                return r.get("res") or {}
        return None

    @staticmethod
    def _safe_crop(img: np.ndarray, bbox: Any, pad: int = 0) -> Optional[np.ndarray]:
        if img is None or bbox is None or not isinstance(bbox, (list, tuple)) or len(bbox) != 4:
            return None
        h, w = img.shape[:2]
        try:
            x1, y1, x2, y2 = map(int, bbox)
        except Exception:
            return None
        x1, y1 = max(0, x1 - pad), max(0, y1 - pad)
        x2, y2 = min(w, x2 + pad), min(h, y2 + pad)
        if x2 <= x1 or y2 <= y1:
            return None
        return img[y1:y2, x1:x2].copy()

    def _cells_from_pp_table(self, rec_res: List[Any], cell_bbox: List[Any], boxes: Any) -> List[Dict[str, Any]]:
        if not rec_res:
            return []
        bbox_list = None
        if isinstance(cell_bbox, list) and len(cell_bbox) == len(rec_res):
            bbox_list = cell_bbox
        elif isinstance(boxes, (list, tuple)) and len(boxes) == len(rec_res):
            bbox_list = boxes
        if bbox_list is None:
            return []

        cells: List[Dict[str, Any]] = []
        for t, b in zip(rec_res, bbox_list):
            text, score = self._extract_text_score(t)
            if not text:
                continue
            xyxy = self._bbox_to_xyxy(b)
            if xyxy is None:
                continue
            x1, y1, x2, y2 = xyxy
            cells.append(
                {"text": text, "score": score, "x1": float(x1), "y1": float(y1),
                 "x2": float(x2), "y2": float(y2), "xc": (x1 + x2) / 2.0, "yc": (y1 + y2) / 2.0}
            )
        return cells

    def _grid_from_cells(self, cells: List[Dict[str, Any]]) -> Optional[List[List[str]]]:
        if not cells:
            return None
        cells_sorted = sorted(cells, key=lambda c: (c["yc"], c["xc"]))
        y_thr = self._auto_y_threshold([c["yc"] for c in cells_sorted])

        rows: List[List[Dict[str, Any]]] = []
        cur: List[Dict[str, Any]] = [cells_sorted[0]]
        cur_y = cells_sorted[0]["yc"]
        for cell in cells_sorted[1:]:
            if abs(cell["yc"] - cur_y) <= y_thr:
                cur.append(cell)
                cur_y = float(np.median([c["yc"] for c in cur]))
            else:
                rows.append(cur)
                cur = [cell]
                cur_y = cell["yc"]
        rows.append(cur)
        for r in rows:
            r.sort(key=lambda c: c["xc"])

        anchor_row = max(rows, key=lambda r: len(r))
        col_x = [c["xc"] for c in anchor_row]
        if not col_x:
            return None

        col_x = self._merge_close_1d(
            col_x,
            min_gap=max(
                8.0,
                float(np.median(np.diff(sorted(col_x))) if len(col_x) > 1 else 15.0) * 0.35
            )
        )
        ncols = len(col_x)
        if ncols <= 0:
            return None

        grid: List[List[str]] = []
        for r in rows:
            row_out = [""] * ncols
            for cell in r:
                j = int(np.argmin([abs(cell["xc"] - x) for x in col_x]))
                row_out[j] = (row_out[j] + " " + cell["text"]).strip() if row_out[j] else cell["text"]
            if any(v.strip() for v in row_out):
                grid.append(row_out)
        return grid if grid else None

    @staticmethod
    def _merge_close_1d(xs: List[float], min_gap: float) -> List[float]:
        xs = sorted(xs)
        out = [xs[0]]
        for x in xs[1:]:
            if abs(x - out[-1]) <= min_gap:
                out[-1] = (out[-1] + x) / 2.0
            else:
                out.append(x)
        return out

    @staticmethod
    def _auto_y_threshold(y_coords: List[float]) -> float:
        if not y_coords or len(y_coords) < 2:
            return 15.0
        ys = sorted(set(float(y) for y in y_coords))
        if len(ys) < 2:
            return 15.0
        diffs = np.diff(ys)
        med = float(np.median(diffs)) if len(diffs) else 15.0
        return max(6.0, min(30.0, med * 0.45))

    def _ensure_header_row(self, grid: List[List[str]]) -> List[List[str]]:
        if not grid:
            return [["COL1"]]
        first = [self._clean_cell(x) for x in grid[0]]
        if self._looks_like_header(first):
            return [first] + [[self._clean_cell(x) for x in r] for r in grid[1:]]
        ncols = max((len(r) for r in grid), default=len(first))
        header = [f"COL{i+1}" for i in range(ncols)]
        fixed: List[List[str]] = [header]
        for r in grid:
            rr = [self._clean_cell(x) for x in r] + [""] * (ncols - len(r))
            fixed.append(rr[:ncols])
        return fixed

    def _looks_like_header(self, row: List[str]) -> bool:
        text = " ".join(row).lower()
        hits = sum(1 for kw in self.HEADER_KEYWORDS if kw in text)
        return hits >= 2

    @staticmethod
    def _clean_cell(x: Any) -> str:
        if x is None:
            return ""
        return str(x).strip()

    @staticmethod
    def _extract_text_score(item: Any) -> Tuple[str, Optional[float]]:
        if item is None:
            return "", None
        if isinstance(item, dict):
            txt = item.get("text") or item.get("transcription") or ""
            score = item.get("score") or item.get("confidence")
            try:
                score = float(score) if score is not None else None
            except Exception:
                score = None
            return str(txt).strip(), score
        if isinstance(item, (list, tuple)):
            if len(item) >= 2 and isinstance(item[0], str):
                txt = item[0]
                score = item[1]
                try:
                    score = float(score) if score is not None else None
                except Exception:
                    score = None
                return str(txt).strip(), score
            if len(item) >= 1 and isinstance(item[0], str):
                return item[0].strip(), None
        return "", None

    @staticmethod
    def _bbox_to_xyxy(bbox: Any) -> Optional[Tuple[float, float, float, float]]:
        if bbox is None:
            return None
        if isinstance(bbox, (list, tuple)) and len(bbox) == 8 and all(isinstance(v, (int, float)) for v in bbox):
            xs = [float(bbox[i]) for i in range(0, 8, 2)]
            ys = [float(bbox[i]) for i in range(1, 8, 2)]
            return min(xs), min(ys), max(xs), max(ys)
        if isinstance(bbox, (list, tuple)) and len(bbox) == 4 and all(isinstance(v, (int, float)) for v in bbox):
            x1, y1, x2, y2 = bbox
            return float(x1), float(y1), float(x2), float(y2)
        if isinstance(bbox, (list, tuple)) and len(bbox) == 4 and all(isinstance(p, (list, tuple)) and len(p) == 2 for p in bbox):
            xs = [float(p[0]) for p in bbox]
            ys = [float(p[1]) for p in bbox]
            return min(xs), min(ys), max(xs), max(ys)
        return None

    def _parse_html_table(self, html: str) -> Optional[List[List[str]]]:
        try:
            if not html or "<table" not in html.lower():
                return None
            dfs = pd.read_html(StringIO(html))
            if not dfs:
                return None
            df = dfs[0]
            header = [str(c).strip() for c in df.columns]
            rows_list = [header]
            for _, row in df.iterrows():
                rows_list.append([str(v).strip() for v in row.values])
            return rows_list if len(rows_list) > 1 else None
        except Exception as e:
            logger.debug(f"âš ï¸ HTML parsing failed: {e}")
            return None

    @staticmethod
    def _tokens_from_rec_res(rec_res: List[Any]) -> List[str]:
        tokens: List[str] = []
        for item in rec_res or []:
            txt, _ = PaddleExtractor._extract_text_score(item)
            if txt:
                tokens.append(txt)
        return tokens

    def _parse_results(self, doc_result: List[Dict[str, Any]], table_blocks: List[Dict[str, Any]]) -> Dict[str, Any]:
        text_lines: List[str] = []
        confidences: List[float] = []
        for region in doc_result:
            if region.get("type") == "table":
                continue
            region_res = region.get("res")
            if isinstance(region_res, tuple) and len(region_res) == 2:
                _boxes, rec_res = region_res
                for item in rec_res or []:
                    txt, score = self._extract_text_score(item)
                    if txt:
                        text_lines.append(txt)
                    if score is not None:
                        confidences.append(float(score))
            elif isinstance(region_res, list):
                for item in region_res:
                    txt, score = self._extract_text_score(item)
                    if txt:
                        text_lines.append(txt)
                    if score is not None:
                        confidences.append(float(score))
            elif isinstance(region_res, dict):
                txt = region_res.get("text") or region_res.get("transcription")
                if txt:
                    text_lines.append(str(txt).strip())
                score = region_res.get("score") or region_res.get("confidence")
                if score is not None:
                    try:
                        confidences.append(float(score))
                    except Exception:
                        pass

        full_text_str = "\n".join([t for t in text_lines if t]).strip()
        fields = self._extract_key_fields(full_text_str)
        avg_confidence = float(np.mean(confidences)) if confidences else 0.0
        return {
            "tables": table_blocks,
            "full_text": full_text_str,
            "fields": fields,
            "confidence_score": avg_confidence,
            "table_count": len(table_blocks),
            "text_items": len(text_lines),
        }

    @staticmethod
    def grid_to_html(grid: List[List[str]]) -> str:
        if not grid:
            return ""
        html_parts = ['<table border="1" cellpadding="5" cellspacing="0">']
        for row in grid:
            html_parts.append("<tr>")
            for cell_text in row:
                safe_text = (
                    str(cell_text)
                    .replace("&", "&amp;")
                    .replace("<", "&lt;")
                    .replace(">", "&gt;")
                    .replace('"', "&quot;")
                )
                html_parts.append(f"<td>{safe_text}</td>")
            html_parts.append("</tr>")
        html_parts.append("</table>")
        return "\n".join(html_parts)

    @staticmethod
    def _extract_key_fields(text: str) -> Dict[str, Optional[str]]:
        fields: Dict[str, Optional[str]] = {}

        inv_patterns = [
            r"(?:Invoice|Bill|Invoice No|Inv|INV)[\s#:]*([A-Z0-9\-\/]+)",
            r"(?:Invoice Number)[\s:]*([0-9A-Z\-\/]+)",
        ]
        fields["invoice_number"] = None
        for pattern in inv_patterns:
            m = re.search(pattern, text, re.IGNORECASE)
            if m:
                fields["invoice_number"] = m.group(1).strip()
                break

        date_patterns = [
            r"(?:Date|Dated)[\s:]*(\d{1,2}[-/]\d{1,2}[-/]\d{4})",
            r"(\d{4}-\d{1,2}-\d{1,2})",
        ]
        fields["date"] = None
        for pattern in date_patterns:
            m = re.search(pattern, text)
            if m:
                fields["date"] = m.group(1)
                break

        amount_patterns = [
            r"(?:Total|Grand Total|Amount Due|TOTAL)[\s:]*[â‚¹$]?\s*([0-9,]+\.?\d*)",
            r"[â‚¹$]\s*([0-9,]+\.?\d*)",
        ]
        fields["total_amount"] = None
        for pattern in amount_patterns:
            m = re.search(pattern, text, re.IGNORECASE)
            if m:
                fields["total_amount"] = m.group(1).strip()
                break

        gstin_match = re.search(r"(?:GSTIN|GST)[\s:]*([0-9A-Z]{15})", text, re.IGNORECASE)
        fields["gstin"] = gstin_match.group(1) if gstin_match else None

        po_match = re.search(r"(?:PO|P\.O\.|Purchase Order)[\s#:]*([A-Z0-9\-]+)", text, re.IGNORECASE)
        fields["po_number"] = po_match.group(1) if po_match else None

        due_date_patterns = [
            r"(?:Due Date|DueDate|Payment Due)[\s:]*(\d{1,2}[-/]\d{1,2}[-/]\d{4})"
        ]
        fields["due_date"] = None
        for pattern in due_date_patterns:
            m = re.search(pattern, text, re.IGNORECASE)
            if m:
                fields["due_date"] = m.group(1)
                break

        vendor_lines = [line.strip() for line in text.split("\n") if len(line.strip()) > 5][:2]
        fields["vendor"] = " ".join(vendor_lines) if vendor_lines else None
        return fields
